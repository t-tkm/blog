<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on My Tech Blog Posts</title>
    <link>https://t-tkm.github.io/blog/tags/aws/</link>
    <description>Recent content in AWS on My Tech Blog Posts</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>&amp;copy; 2021 Takumi Tomita Powered by Hugo &amp; Pickles.</copyright>
    <lastBuildDate>Sun, 13 Mar 2022 00:00:00 +0900</lastBuildDate><atom:link href="https://t-tkm.github.io/blog/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hugoでハンズオンサイト(AWS)</title>
      <link>https://t-tkm.github.io/blog/posts/2022/aws_hugo/</link>
      <pubDate>Sun, 13 Mar 2022 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2022/aws_hugo/</guid>
      <description>はじめに 唐突ですが、AWS Workshopsというサイトをご存知でしょうか？
AWS Workshopsは、AWSが公式に提供しているハンズオンコンテンツで、AWS各種サービスについて、実際に手を動かしてみたい場合に大変重宝するサイトです。
https://workshops.aws/
さてこのサイト、とてもお洒落な作りになっていますが、どのように作られているのでしょうか？
答えは、Hugoと言われるGo製の静的サイトジェネレータと、Learnと呼ばれるテーマ(Theme)を使って作られているようです。
 https://gohugo.io/ https://jamstackthemes.dev/theme/hugo-theme-learn/  実はこのAWS Workshopsに。このようなハンズオンサイトの作り方のハンズオンがあります！折角なので、試してみたいと思います。
https://hosting-hugo-content.workshop.aws/
  ※ハンズオンの主目的は、Hugoの使い方でなく、AWS Amplifyを活用したホスティングサイト構築手法(CICD込み)ですw
Hugoセットアップ 詳細はハンズオンを見てもらうとして、Cloud9を使っていきます。初めにHugoをインストールします。Goで作られたシングルバイナリなので、ダウンロード後に解凍し、パスの通ったディレクトリへ実行ファイルを置くだけで利用できます。
$ wget https://github.com/gohugoio/hugo/releases/download/v0.71.0/hugo_extended_0.71.0_Linux-64bit.tar.gz -O hugo_extended_0.71.0_Linux-64bit.tar.gz $ HUGO_TAR=&amp;#34;$(find . -name &amp;#34;*Linux-64bit.tar.gz&amp;#34;)&amp;#34; $ tar -xzf $HUGO_TAR $ chmod +x hugo $ mkdir bin $ mv hugo bin/ $ cd ~/environment/ # Hugoがインストールできているかの確認 $ hugo version Hugo Static Site Generator v0.71.0-06150C87/extended linux/amd64 BuildDate: 2020-05-18T16:15:29Z サンプルサイトの確認 # 事前に、Hugoで作ったサンプルサイトをダウンロードします $ git clone -b v1.0 --single-branch https://github.</description>
    </item>
    
    <item>
      <title>AWS App2Container(お試し編)</title>
      <link>https://t-tkm.github.io/blog/posts/2022/aws_app2container/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2022/aws_app2container/</guid>
      <description>はじめに AWS App2Containerは、起動中のjavaアプリをコンテナイメージに変換し、ECSやEKSで稼働させるためのテンプレートを生成するツールになります。
Accelerating your Migration to AWS
  下記、App2ContainerのUerGuideにある通り、サポートされるプラットフォームと、そうでない場合で挙動が変わるため、本記事ではその辺を試してみたいと思います(ここでは、ECSやEKSでの稼働検証は含まれません)。
 For supported application frameworks, App2Container targets only the application files and dependencies that are needed for containerization, thereby minimizing the size of the resulting container image. This is known as application mode.
  If App2Container does not find a supported framework running on your application server, or if you have other dependent processes running on your server, App2Container takes a conservative approach to identifying dependencies.</description>
    </item>
    
    <item>
      <title>AWS App2Container(イメージ最適化編)</title>
      <link>https://t-tkm.github.io/blog/posts/2022/aws_app2container_opt/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2022/aws_app2container_opt/</guid>
      <description>はじめに 前回(「AWS App2Container(お試し編)」)で試した非サポートアプリの場合(ex. SpringBootアプリ)、サポートされるtomcatアプリと比較すると(802MB)、デフォルトで生成されたコンテナイメージは16.1GBとかなりのサイズとなっていました。
  root@ip-10-0-1-112:~# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE java-generic-6ef9339e latest 8ef7ef3e7db0 38 minutes ago 16.1GB java-tomcat-5da060de latest cc2de1db6ef8 58 minutes ago 802MB そこで、ここでは、下記ガイドラインに従いサイズをスリム化してみようと思います。
Optimize AWS App2Container generated Docker images
ポイントは、App2Containerは、分析結果であるanalysis.jsonをベースにイメージを生成するため、不要なファイルを含めないようにanalysis.jsonを編集することになります。   コンテナイメージ分析(dive) はじめに、コンテナイメージの中身を確認できるdiveというツールを導入して、既存のコンテナイメージを分析してみます。
root@ip-10-0-1-112:~# wget https://github.com/wagoodman/dive/releases/download/v0.9.2/dive_0.9.2_linux_amd64.deb root@ip-10-0-1-112:~# apt install ./dive_0.9.2_linux_amd64.deb root@ip-10-0-1-112:~# dpkg -l | grep dive ii dive 0.9.2 amd64 no description given root@ip-10-0-1-112:~# dive --version dive 0.9.2 使い方は簡単で、解析したいコンテナイメージ名とタグ(option)をdiveコマンドの引数に指定するだけです。
 this can take a while for large images</description>
    </item>
    
    <item>
      <title>Alexaでかけ算ゲーム</title>
      <link>https://t-tkm.github.io/blog/posts/2021/03/aws_alexa_practice/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2021/03/aws_alexa_practice/</guid>
      <description>Alexaでかけ算ゲーム はじめに 今年の正月は、コロナ禍ということで帰省ができなかったため、以前より気になっていたAlexaに手を出してみました。あわよくば、今回の勉強を通して「Alexa認定」も取得できるかも？と思ったのですが、そこまで甘い世界ではありませんでした1。。。
Alexa全体像の理解 さて、実際始めようとすると、今まで公私共に全く触った事の無いサービスという事もあり、どこから手をつけてよいものかわかりません。。。そこでとっかかりとして、Alexa公式 動画シリーズ「Alexa道場」から始めることにしました。こちらの教材がとても丁寧で、ストーリを追って段階的に学習できお勧めです！一通り動画を視聴し終わると、なんとなく(開発含めた)全体像が把握できると思います(とりあえずスキルを作ってみたいというのであれば、Season1〜3で十分)。
#スキル開発 では早速開発、と言ってもゼロベースでコードを作成するのは流石に大変ですで、お手本になるサンプル探しを開始。そこで気がついた事は、Alexaのスキル自体はたくさん公開されているのですが、コードはさほどネットには落ちてない感じでした(私の探し方が十分で無い可能性もございます)。そこで見つけたのが、クジラ飛行机さんのやさしくはじめる スマートスピーカープログラミング。このサンプルをベースに、スキル作成にチャレンジさせて頂きました。
ユースケース ちょうど、小学２年の息子が「冬休みの宿題」として九九の練習を持ち帰ってきており、親が問題を出すという箇所を、Alexaにお手伝いしてもらうことにしました。   実際のアクター(息子)とシステム(Alexa)のやりとりは↓   システム概要 今回はじめて知ったのですが、AlexaサービスはAWSでなくAmazonなのですね。また、Alexaを開発するコンソールも、日々進化しているようで、書籍・記事によっては追い付けていないものも多いと思われますので、最新がどうなっているのか確認が必要になります(Alexaに限らず、クラウドサービス全般に言えることではございます)。
  サンプル(lambda) 今回作成したコードは、こちらに置いております。 https://gitlab.com/t-tkm/alexa-kakezan-game
const Alexa = require(&amp;#39;ask-sdk&amp;#39;); const TABLE_NAME = &amp;#39;myScore&amp;#39;; let skill; exports.handler = async function (event, context) { if (skill) return skill.invoke(event); skill = Alexa.SkillBuilders.standard() .addRequestHandlers( LaunchRequestHandler, NumberIntentHandler, CancelIntentHandler) .withTableName(TABLE_NAME) .withAutoCreateTable(true) .create(); return skill.invoke(event); }; const TITLE = &amp;#39;かけ算ゲーム&amp;#39;; function getResponse(h, msg) { return h.responseBuilder .speak(msg).reprompt(msg).withSimpleCard(TITLE, msg) .getResponse(); } async function getHighScore(h) { const pa = await h.</description>
    </item>
    
    <item>
      <title>我が家のマイクラサーバー(AWS編)</title>
      <link>https://t-tkm.github.io/blog/posts/2021/03/minecraft_server_aws_ecs/</link>
      <pubDate>Sun, 21 Mar 2021 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2021/03/minecraft_server_aws_ecs/</guid>
      <description>はじめに マイクラサーバ(javaアプリ)をECS+Fargate+EFSで動かしてみた備忘録になります。趣味であるこのシステムの運用を通じて、今後周辺ノウハウを強化していきたいというのが(私、インフラエンジニア)目的ですw
我が家はマイクラのヘビーユーザで、息子3人(小学生)と母親が、同じ世界(マイクラではワールドと呼ぶ)にログインして、各々の建築を見せあったり、道具を揃えて洞窟を冒険したり楽しんでいます。私はそのマルチサーバをお守りしており、以前はVM上にサーバを構築して運用していました。しかし、1つのサーバで展開できるワールドは1つであり、色々複数のワールドを家族に提供するには、複数サーバを立てる必要があります。そこで、最近ではアプリをitzg氏が作成・メンテしているコンテナ1を使い、複数ワールドをフットプリント軽く運用していました。
ECS+Fargateに目をつけた理由 VMにDockerをインストールして、複数コンテナを運用していたのですが「Fargateを使えばVMのメンテが不要になるのでは？」と漠然と考えていました。しかし、マイクラサーバは、ワールドデータを自身のディスク(ファイルシステム)に永続化する必要があるため、Fargateでは諦めていたところ、2020.4月にFargateがEFSをサポート！というアナウンスを受け、これは試すしかないと思ったのがきっかけになります。 ※試してみたのは昨年4月なのですが、今頃記事を書いているのは単に私の怠慢ですw
注意  サーバー運営で発生するリスクは全て自己責任でお願いします。Mineraftに限る話ではないですが、サーバ構築・動作には様々なリスクがあります。自身が何をしているのか十分理解する必要があります。 また、Minecraftの利用規約やガイドラインについても確認するようにして下さい(例えばこちら)。規約にある通り、全般的に個人で楽しむ使い方には好意的に見受けられますが、一方でビジネス(お金儲け)についての利用は厳しく線引き(制限)されています。  システム概要 マイクラは今や世界的に展開されいるゲームであり、対応プラットフォームもPCだけでなく様々です。ここで記載するのはPCのJava版と呼ばれるエディションによる、クライアント・サーバ形式のものを使い、そのサーバ部分をECS(Fargate)化してみよう、というのがゴールになります。クライアント(プレイヤー)の方は、我が家ではこちらのサイトから、5名分のアカウント(3,000円/人、買切り〜2020.4月地点〜)を購入して楽しんでいます2。
  今回デプロイしてみた構成図は下記になります。   #各種設定概略 以下、概略程度になりますが、各種サービス設定と、その時のポイントを共有したいと思います。
ELBの設定  マイクラサーバはHTTP(S)などL7プロトコルでなく、ポート番号25565を使った独自プロトコル(Java RMI?)になるため、ELBもNLB(L4)を使います 外部からデフォルトポート番号でアクセスさせるのは少し気になったので、外からは50000で受付け、それをアプリ(25565)に転送させています     EFSの設定  特段な事は行わず、素直な設定でいきました     ECSタスクの設定  コンテナイメージは、itgz氏の下記を利用しました  https://hub.docker.com/r/itzg/minecraft-server   タスクサイズは、CPUとして2vCPU(1024x2)と、メモリ4GiBを確保。  今回は、タスクの中に定義するコンテナは1つなのでこれで十分ですが、ロギング用などサイドカーコンテナも一緒に入れておくなど1タスクにに複数コンテナを定義する場合は、個別コンテナに対してリソース制限を設定する事も可能です。ただし、AWSドキュメントにも記載されている通り、あまり神経質になる必要はないようです3。   コンテナの使い方にもある通り、コンテナ起動時に環境変数「EULA=TRUE」が必要です。 アプリデータの永続化に、先に作成したEFSのファイルシステムを指定したボリュームを指定します。アプリ(コンテナ)内のマウントポイントは「/data」です。      ECSサービス設定  2020.4月の段階では、プラットフォームバージョンを「latest」にするとFargateは「1.3.0」で起動し、EFSマウント機能(1.4.0)が使えなかったので明示的に指定していました。最近latestが1.4.0になったようですので↓、今後はlatestで良いのかもしれません。  https://aws.amazon.com/jp/about-aws/whats-new/2021/03/aws-fargate-updates-platform-version-1-4-0-to-be-the-latest-version/   マイクラサーバ(アプリ)はシングルサーバ構成であるため、タスク数は1になります。タスク数を2以上にして複数コンテナを立ち上げようとすると、アプリ側で起動失敗するようになっているようです。**コンテナ化によるオートスケールの恩恵を受けたい場合、アプリもステートレスなどでスケールできる作りにしておく必要がある。**という、分かりやすい例かと思いました。            自動起動・停止ジョブ(lambda)  コンテナの起動、停止もサービス経由で宣言的に操作できるのが嬉しいですね♪  宣言的？ Declarative?</description>
    </item>
    
    <item>
      <title>FireLensを使ってFargateコンテナのファイルログを転送してみた</title>
      <link>https://t-tkm.github.io/blog/posts/2020/07/aws_firelens_practice/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>https://t-tkm.github.io/blog/posts/2020/07/aws_firelens_practice/</guid>
      <description>はじめに 通常はTwelve-Factor Appに「ログをイベントストリームとして扱う」とあるように、コンテナアプリケーションのログは標準出力を集約先とするのが設計原則です。しかし、もともと仮想マシンで動かしていたサーバをコンテナ化しようとする時など、
「まずはアプリケーションコンテナを極力改修せず(ログ出力先を、ファイルから標準出力に変更)になんとかならないか。。。」
というニーズもあるかと思います。ここでは、ファイル出力されたアプリケーションコンテナのログをFireLens(Fluentbit)を使ってCloudWatchへ転送する方法を紹介します。尚、FireLensを使わずとも、サイドカー(Fluentd)を自前で準備する方法として「Fargateで起動するコンテナのログをFluentd経由でS3に保存してみた」というのもあり、ご一緒に確認されると良いかと思います。
検証の流れ 検証は、次の手順で進めています。
 Fluentbitコンテナ作成 :設定ファイルの取込みと、ECRへイメージpush アプリケーションコンテナ作成 : tomcat上にsample.warをデプロイと、ECRへイメージpush Task定義作成 : CloudFormationのテンプレートを準備したので、それを使ってスタック作成 Fargateクラスタ&amp;amp;サービス作成: AWSマネジメントコンソールから操作 アプリケーションへアクセス : ブラウザから ログの確認(Cloud Watch Logs)  システム構成は、こんな感じになります。   また、コンテナをビルドしたりするために使用したファイル(プロジェクト)はこちらです。
$ tree . ├── my-fluentbit │ ├── Dockerfile │ └── extra.conf //Fluentbit用設定ファイル ├── my-tomcat | └── Dockerfile ├── task-def.yaml //Cloud Formationにこのテンプレートファイルを指定して、スタック作成 コンテナイメージ作成 Fluentbitコンテナ Fluentbitの設定ファイル(extra.conf)を作成します。
[INPUT] Name tail Path /usr/local/tomcat/logs/localhost_access_log.*.txt Tag file-app-logs [OUTPUT] Name cloudwatch Match fargate-fluentbit-app* region ap-northeast-1 log_group_name fluentbit-cloudwatch-stdout log_stream_prefix fluentbit-stdout- auto_create_group true [OUTPUT] Name cloudwatch Match file-app-logs* region ap-northeast-1 log_group_name fluentbit-cloudwatch-file log_stream_prefix fluentbit-file- auto_create_group true [補足]tailプラグインではpos_fileで、どのファイルのどの部分まで読込み済みかチェックするための指定ができたりしますが、今回は省略しています。</description>
    </item>
    
  </channel>
</rss>
